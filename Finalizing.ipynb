{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd06f6f-b0ab-42f5-8793-bea72e28b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tavily-python in /opt/anaconda3/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from tavily-python) (0.8.0)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/lib/python3.12/site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken>=0.5.1->tavily-python) (2023.10.3)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx->tavily-python) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx->tavily-python) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx->tavily-python) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tavily-python requests beautifulsoup4 transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5ef5b16-a8a5-45a6-afe8-aef86a6cedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def give_content(query=\"delhi , artifical intelligence\"):\n",
    "    client = TavilyClient(api_key=\"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\")\n",
    "    response = client.search(\n",
    "        query=query,\n",
    "        search_depth=\"advanced\",\n",
    "        topic=\"news\",\n",
    "        time_range=\"year\",\n",
    "        include_images=True\n",
    "    )\n",
    "    for i in response['results']:\n",
    "\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        URL = i['url']\n",
    "        response = requests.get(URL, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "            # Example: Extract all paragraph text\n",
    "            paragraphs = [p.text.strip() for p in soup.find_all('p')]\n",
    "            \n",
    "            # Print extracted text\n",
    "            return paragraphs\n",
    "    print(\"Failed to retrieve the webpage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60cd3889-d209-49d5-a4da-438819acd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = give_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "861221bd-d4b2-4c4d-a064-1fea99e35695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: .  2025 Hyderabad Media House Limited/The Hans India. All rights reserved.\n",
      "Summary: the coEs will be led by top educational institutions, in consortium with industry partners and startups. they will democratise AI innovations and research to revolutionize healthcare delivery, strengthen food security and address critical urban challenges. the interdisciplinary research, develop cutting-edge applications and create scalable solutions in these three areas.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from typing import List, Tuple\n",
    "\n",
    "class TextSummarizer:\n",
    "    def __init__(self, model_name: str = \"t5-small\"):\n",
    "        \"\"\"\n",
    "        Initialize the summarizer with T5 model and tokenizer\n",
    "        Args:\n",
    "            model_name: Name of the T5 model to use (default: 't5-small')\n",
    "        \"\"\"\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "\n",
    "    def preprocess_text(self, paragraphs: List[str], task: str) -> str:\n",
    "        \"\"\"\n",
    "        Combine paragraphs and add prefix for summarization or title generation\n",
    "        Args:\n",
    "            paragraphs: List of paragraph strings\n",
    "            task: Task type ('summarize' or 'title')\n",
    "        Returns:\n",
    "            Preprocessed text ready for processing\n",
    "        \"\"\"\n",
    "        combined_text = \"\\n\".join(paragraphs)\n",
    "        return f\"{task}: {combined_text}\"\n",
    "\n",
    "    def generate_text(self, input_text: str, max_length: int) -> str:\n",
    "        \"\"\"\n",
    "        Generate text using T5 model\n",
    "        Args:\n",
    "            input_text: Input text for the model\n",
    "            max_length: Maximum length of the generated text\n",
    "        Returns:\n",
    "            Generated text\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(self.device)\n",
    "\n",
    "        output_ids = self.model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            num_beams=5,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "\n",
    "        return self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    def summarize_and_title(self, paragraphs: List[str]) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Generate both a summary and a title\n",
    "        Args:\n",
    "            paragraphs: List of paragraph strings\n",
    "        Returns:\n",
    "            Tuple of (summary, title)\n",
    "        \"\"\"\n",
    "        summary = self.generate_text(self.preprocess_text(paragraphs, \"summarize\"), max_length=150)\n",
    "        title = self.generate_text(self.preprocess_text(paragraphs, \"title\"), max_length=20)\n",
    "        return summary, title\n",
    "\n",
    "# Initialize summarizer\n",
    "summarizer = TextSummarizer()\n",
    "\n",
    "# Example usage\n",
    "summary, title = summarizer.summarize_and_title(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3c9c419-491a-4fa1-8ba8-f1e2b1d8e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Define OAuth 2.0 scope\n",
    "SCOPES = [\"https://www.googleapis.com/auth/blogger\"]\n",
    "\n",
    "def authenticate():\n",
    "    \"\"\"Authenticate and get OAuth 2.0 credentials.\"\"\"\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(\n",
    "        \"credentials.json\", SCOPES\n",
    "    )\n",
    "    creds = flow.run_local_server(port=0)\n",
    "    return creds\n",
    "\n",
    "def create_blog_post(creds,title,content):\n",
    "    \"\"\"Create a new blog post using Blogger API.\"\"\"\n",
    "    service = build(\"blogger\", \"v3\", credentials=creds)\n",
    "\n",
    "    blog_id = \"7894317275629685509\"  # Replace with your actual Blog ID\n",
    "    post_body = {\n",
    "        \"title\": title,\n",
    "        \"content\": content\n",
    "    }\n",
    "\n",
    "    post = service.posts().insert(blogId=blog_id, body=post_body).execute()\n",
    "    print(\"Post created:\", post[\"url\"])\n",
    "    return spost[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7315eff-3697-4395-a5e0-5f94244a32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=183208013542-6kfpqdql03aoljkv0ehbemj69h6jp1vn.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A57105%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fblogger&state=MUbjdoVDNrZ3QIoYmH2G9BiTqdqmcy&access_type=offline\n",
      "Post created: http://newsflipr.blogspot.com/2025/02/2025-hyderabad-media-house-limitedthe.html\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create a post\n",
    "creds = authenticate()\n",
    "link_to_website = create_blog_post(creds,title,summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd17b7ec-3b2e-4dea-913c-e3ae368d32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(link_to_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685927e-7973-486f-8a5e-270168e8e706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
